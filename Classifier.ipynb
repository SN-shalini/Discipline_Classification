{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dbac678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,accuracy_score, precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13dfded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable declarations\n",
    "\n",
    "embeddings_list = []\n",
    "label_list = []\n",
    "unique_label_name = []\n",
    "accuracy_list = []\n",
    "# model_list = [\n",
    "#     ('Logistic Regression', LogisticRegression()),      \n",
    "#     ('K Nearest Neighbor', KNeighborsClassifier()),\n",
    "#     ('Random Forest', RandomForestClassifier(random_state=3))]\n",
    "\n",
    "# pipeline = Pipeline(model_list)\n",
    "\n",
    "model_dict = {'K Nearest Neighbor': KNeighborsClassifier(n_neighbors= 3 , weights = 'distance'),\n",
    "              'Logistic Regression': LogisticRegression(),\n",
    "             'Random Forest': RandomForestClassifier(random_state=3,max_depth=20, criterion = \"entropy\"),\n",
    "             'Decsision Tree': DecisionTreeClassifier(random_state=3, max_depth=20)}\n",
    "\n",
    "model_comparison_df = pd.DataFrame(columns = ['model_name', 'train_accuracy', 'test_accuracy_score', 'precision_score', 'recall_score', 'f1_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d35586db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_embeddings():\n",
    "    data_folder = \"Embeddings/Embeddings--bge-large-en\"\n",
    "    global embeddings_list\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(\"Error: Data folder does not exists.\")\n",
    "\n",
    "    data = [os.path.join(data_folder, file) for file in os.listdir(data_folder)]\n",
    "    \n",
    "    for filepath in data: \n",
    "        data = filepath.split('/')\n",
    "        label_name = data[-1].removesuffix(\".npy\")\n",
    "        unique_label_name.append(label_name)\n",
    "        with open (filepath, 'rb') as fp:\n",
    "            embeddings = np.load(fp)\n",
    "            embeddings_list.append(embeddings)\n",
    "            size = len(embeddings)\n",
    "            for label in range(0, size):\n",
    "                label_list.append(label_name)\n",
    "\n",
    "    embeddings_list = np.concatenate(embeddings_list, axis = 0)\n",
    "\n",
    "    return embeddings_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2374e2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embeddings/Embeddings--bge-large-en/Earth Sciences.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Pharmacy.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Environment.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Mathematics.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Life Sciences.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Philosophy.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Economics.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Law.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Biomedicine.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Computer Science.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Literature.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Materials Science.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Chemistry.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Statistics.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/History.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Social Sciences.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Political Science and International Relations.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Psychology.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Physics.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Geography.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Engineering.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Medicine & Public Health.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Business and Management.npy',\n",
       " 'Embeddings/Embeddings--bge-large-en/Education.npy']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    data_folder = \"Embeddings/Embeddings--bge-large-en\"\n",
    "    data = [os.path.join(data_folder, file) for file in os.listdir(data_folder)]\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c072f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    X_train, X_test = train_test_split(embeddings_list, test_size = 0.2, random_state=42)\n",
    "    y_train, y_test = train_test_split(label_list, test_size=0.2, random_state=42)\n",
    "    model_name, train_accuracy, test_accuracy, precision, recall, f1score = [], [], [], [], [], []\n",
    "\n",
    "    for name, model in model_dict.items():\n",
    "        model_name.append(name)\n",
    "\n",
    "        model.fit(X_train, y_train)        \n",
    "        y_pred = model.predict(X_test)  \n",
    "\n",
    "        train_accuracy.append(model.score(X_train, y_train))\n",
    "        test_accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1score.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    model_comparison_df = pd.DataFrame(data=zip(model_name,train_accuracy,test_accuracy,precision,recall,f1score),\n",
    "                                       columns = ['model_name', 'train_accuracy', 'test_accuracy_score', 'precision_score', 'recall_score', 'f1_score']) \n",
    "    \n",
    "    model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "        \n",
    "    return model_comparison_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181322\n",
      "['Earth Sciences', 'Pharmacy', 'Environment', 'Mathematics', 'Life Sciences', 'Philosophy', 'Economics', 'Law', 'Biomedicine', 'Computer Science', 'Literature', 'Materials Science', 'Chemistry', 'Statistics', 'History', 'Social Sciences', 'Political Science and International Relations', 'Psychology', 'Physics', 'Geography', 'Engineering', 'Medicine & Public Health', 'Business and Management', 'Education']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shalini_tiwari/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "    discipline_embeddings = get_labels_and_embeddings()\n",
    "    print(len(discipline_embeddings))\n",
    "    print(unique_label_name)\n",
    "\n",
    "    model_comparison_df = train_model()\n",
    "    print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34313dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_comparison_df.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(model_comparison_df, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_comparison_df.pkl\", \"rb\") as fout:\n",
    "    df = pickle.load(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4d3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
